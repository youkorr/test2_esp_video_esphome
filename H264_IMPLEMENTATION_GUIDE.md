# Guide d'implÃ©mentation H.264 sur ESP32-P4

## ğŸ¯ Vue d'ensemble

L'ESP32-P4 dispose d'un **encodeur H.264 hardware** qui peut encoder des vidÃ©os en temps rÃ©el. Votre projet a dÃ©jÃ  le composant `esp_h264` intÃ©grÃ© et l'infrastructure est en place dans `mipi_dsi_cam`.

## ğŸ“Š Architecture VidÃ©o

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    RAW8     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    RGB565/YUV420    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  SC202CS    â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€> â”‚   ISP    â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€> â”‚   Output     â”‚
â”‚  Sensor     â”‚  MIPI CSI   â”‚/dev/videoâ”‚                     â”‚              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚   20     â”‚                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                              â”‚
                                                                      â”‚
                          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
                          â”‚                                          â”‚
                          v                                          v
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚   JPEG    â”‚                              â”‚   H.264   â”‚
                    â”‚ /dev/videoâ”‚                              â”‚/dev/video â”‚
                    â”‚    10     â”‚                              â”‚    11     â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ”‘ Points ClÃ©s

### 1. Formats de Pixels

| Format  | Usage                    | Devices                |
|---------|--------------------------|------------------------|
| RAW8    | Sensor â†’ ISP             | CamÃ©ra MIPI CSI        |
| RGB565  | Display LVGL             | ISP â†’ Display          |
| YUV420  | H.264 Encoder (REQUIS)   | ISP â†’ H.264 encoder    |
| YUYV    | Alternative YUV422       | ISP â†’ JPEG/H.264       |

### 2. Pipeline H.264

**ProblÃ¨me actuel** : Votre systÃ¨me capture en **RGB565** pour LVGL display.
**Pour H.264** : Il faut capturer en **YUV420** (format requis par H.264 hardware encoder).

**Solutions possibles** :

#### Option A : Dual Pipeline (RECOMMANDÃ‰)
- Pipeline 1 : RAW8 â†’ ISP â†’ RGB565 â†’ LVGL Display (30 FPS)
- Pipeline 2 : RAW8 â†’ ISP â†’ YUV420 â†’ H.264 Encoder â†’ Stream (30 FPS)

**Avantages** :
- Display et streaming simultanÃ©s
- Performance optimale (2 pipelines indÃ©pendants)

**InconvÃ©nients** :
- Plus complexe Ã  implÃ©menter
- Consommation mÃ©moire doublÃ©e

#### Option B : Single Pipeline avec conversion
- Pipeline : RAW8 â†’ ISP â†’ YUV420 â†’ Display + H.264

**Avantages** :
- Simple Ã  implÃ©menter
- Une seule capture

**InconvÃ©nients** :
- NÃ©cessite conversion YUV420 â†’ RGB565 pour display (coÃ»t CPU)
- Ou utiliser LVGL avec format YUV (support limitÃ©)

#### Option C : Alternance Display/Stream
- Frame paire : RGB565 â†’ Display
- Frame impaire : YUV420 â†’ H.264

**Avantages** :
- Compromis ressources/performance
- Pas de duplication de pipeline

**InconvÃ©nients** :
- FPS effectif rÃ©duit de moitiÃ© (15 FPS display, 15 FPS stream)

## ğŸš€ ImplÃ©mentation RecommandÃ©e (Option A)

### Ã‰tape 1 : Configuration YAML

```yaml
# Dans votre fichier ESPHome YAML
mipi_dsi_cam:
  id: main_camera
  i2c_id: bsp_bus
  sensor_type: sc202cs
  resolution: "1280x720"
  pixel_format: "YUV420"  # â† Changer de RGB565 Ã  YUV420
  framerate: 30

# Nouveau composant pour streaming H.264
h264_stream:
  id: h264_streamer
  camera_id: main_camera
  bitrate: 2000000  # 2 Mbps
  gop: 30
  quality: 25  # QP (Quantization Parameter) : 0=meilleur, 51=pire

  # Sortie stream (exemples)
  output:
    - http_server:  # Servir via HTTP
        port: 8080
        path: "/stream.h264"
    - mqtt:  # Publier via MQTT
        topic: "esphome/camera/h264"
    - websocket:  # WebSocket pour navigateur
        port: 8081
```

### Ã‰tape 2 : CrÃ©er le composant `h264_stream`

Il faut crÃ©er un nouveau composant ESPHome pour gÃ©rer le streaming H.264 :

**Fichier : `components/h264_stream/h264_stream.h`**

```cpp
#pragma once

#include "esphome/core/component.h"
#include "esphome/components/mipi_dsi_cam/mipi_dsi_cam.h"
#include "esp_h264_enc_single.h"

namespace esphome {
namespace h264_stream {

class H264StreamComponent : public Component {
 public:
  void setup() override;
  void loop() override;
  void dump_config() override;

  void set_camera(mipi_dsi_cam::MipiDSICamComponent *camera) { camera_ = camera; }
  void set_bitrate(uint32_t bitrate) { bitrate_ = bitrate; }
  void set_gop(uint8_t gop) { gop_ = gop; }
  void set_quality(uint8_t quality) { quality_ = quality; }

  // Callbacks pour diffÃ©rents outputs
  void add_data_callback(std::function<void(const uint8_t*, size_t)> callback);

 protected:
  mipi_dsi_cam::MipiDSICamComponent *camera_{nullptr};

  esp_h264_enc_handle_t h264_encoder_{nullptr};
  uint8_t *encoded_buffer_{nullptr};
  size_t encoded_buffer_size_{0};

  uint32_t bitrate_{2000000};
  uint8_t gop_{30};
  uint8_t quality_{25};

  std::vector<std::function<void(const uint8_t*, size_t)>> data_callbacks_;

  bool encode_frame_();
};

}  // namespace h264_stream
}  // namespace esphome
```

**Fichier : `components/h264_stream/h264_stream.cpp`**

```cpp
#include "h264_stream.h"
#include "esphome/core/log.h"

namespace esphome {
namespace h264_stream {

static const char *const TAG = "h264_stream";

void H264StreamComponent::setup() {
  ESP_LOGCONFIG(TAG, "Setting up H.264 Stream...");

  if (this->camera_ == nullptr) {
    ESP_LOGE(TAG, "Camera not configured");
    this->mark_failed();
    return;
  }

  // Configurer l'encodeur H.264
  esp_h264_enc_cfg_hw_t encoder_cfg = {
    .width = this->camera_->get_image_width(),
    .height = this->camera_->get_image_height(),
    .src_rate = 30,  // FPS source
    .dst_rate = 30,  // FPS encodÃ©
    .gop = this->gop_,
    .qp_max = this->quality_ + 1,
    .qp_min = this->quality_,
    .bitrate = this->bitrate_,
    .input_format = ESP_H264_RAW_FMT_O_UYY_E_VYY,  // YUV420
  };

  esp_h264_err_t ret = esp_h264_enc_open(&encoder_cfg, &this->h264_encoder_);
  if (ret != ESP_H264_ERR_OK) {
    ESP_LOGE(TAG, "Failed to open H.264 encoder: %d", ret);
    this->mark_failed();
    return;
  }

  // Allouer buffer de sortie H.264
  this->encoded_buffer_size_ = encoder_cfg.width * encoder_cfg.height / 2;  // Estimation
  this->encoded_buffer_ = (uint8_t*)heap_caps_malloc(
    this->encoded_buffer_size_,
    MALLOC_CAP_SPIRAM | MALLOC_CAP_8BIT
  );

  if (this->encoded_buffer_ == nullptr) {
    ESP_LOGE(TAG, "Failed to allocate H.264 output buffer");
    this->mark_failed();
    return;
  }

  ESP_LOGI(TAG, "âœ… H.264 Stream initialized");
  ESP_LOGI(TAG, "   Resolution: %ux%u", encoder_cfg.width, encoder_cfg.height);
  ESP_LOGI(TAG, "   Bitrate: %u bps (%.2f Mbps)", this->bitrate_, this->bitrate_ / 1000000.0f);
  ESP_LOGI(TAG, "   GOP: %u frames", this->gop_);
  ESP_LOGI(TAG, "   Quality (QP): %u", this->quality_);
}

void H264StreamComponent::loop() {
  if (!this->camera_->is_streaming()) {
    return;
  }

  // Encoder une frame
  if (this->encode_frame_()) {
    // Notifier tous les callbacks (HTTP, MQTT, WebSocket, etc.)
    for (auto &callback : this->data_callbacks_) {
      callback(this->encoded_buffer_, this->encoded_buffer_size_);
    }
  }
}

bool H264StreamComponent::encode_frame_() {
  // RÃ©cupÃ©rer frame YUV420 depuis la camÃ©ra
  mipi_dsi_cam::SimpleBufferElement *buffer = nullptr;
  uint8_t *yuv_data = nullptr;
  int width, height;

  if (!this->camera_->get_current_rgb_frame(&buffer, &yuv_data, &width, &height)) {
    return false;
  }

  // Encoder la frame
  esp_h264_enc_in_frame_t in_frame = {
    .raw_data = {
      .buffer = yuv_data,
      .len = width * height * 3 / 2,  // YUV420 = 1.5 bytes/pixel
    }
  };

  esp_h264_enc_out_frame_t out_frame = {
    .raw_data = {
      .buffer = this->encoded_buffer_,
      .len = this->encoded_buffer_size_,
    }
  };

  esp_h264_err_t ret = esp_h264_enc_process(this->h264_encoder_, &in_frame, &out_frame);

  // LibÃ©rer le buffer camÃ©ra
  this->camera_->release_buffer(buffer);

  if (ret != ESP_H264_ERR_OK) {
    ESP_LOGW(TAG, "H.264 encoding failed: %d", ret);
    return false;
  }

  this->encoded_buffer_size_ = out_frame.length;
  return true;
}

void H264StreamComponent::add_data_callback(std::function<void(const uint8_t*, size_t)> callback) {
  this->data_callbacks_.push_back(callback);
}

void H264StreamComponent::dump_config() {
  ESP_LOGCONFIG(TAG, "H.264 Stream:");
  ESP_LOGCONFIG(TAG, "  Resolution: %ux%u",
    this->camera_->get_image_width(),
    this->camera_->get_image_height());
  ESP_LOGCONFIG(TAG, "  Bitrate: %u bps", this->bitrate_);
  ESP_LOGCONFIG(TAG, "  GOP: %u", this->gop_);
  ESP_LOGCONFIG(TAG, "  Quality: %u", this->quality_);
}

}  // namespace h264_stream
}  // namespace esphome
```

## ğŸ“ Configuration ComplÃ¨te

### YAML Example

```yaml
# Configuration complÃ¨te avec H.264 streaming
esphome:
  name: esp32-p4-camera

esp32:
  board: esp32-p4-function-ev-board
  variant: esp32p4
  framework:
    type: esp-idf

# DÃ©pendances externes
external_components:
  - source: github://your-repo/esphome-components
    components: [ mipi_dsi_cam, h264_stream, esp_video, esp_h264 ]

# Configuration camÃ©ra
i2c:
  - id: bsp_bus
    sda: GPIO8
    scl: GPIO9
    frequency: 400kHz

# CamÃ©ra MIPI avec sortie YUV420
mipi_dsi_cam:
  id: main_camera
  i2c_id: bsp_bus
  sensor_type: sc202cs
  resolution: "1280x720"
  pixel_format: "YUV420"  # â† IMPORTANT pour H.264
  framerate: 30

# Streaming H.264
h264_stream:
  id: video_stream
  camera_id: main_camera
  bitrate: 2000000  # 2 Mbps
  gop: 30
  quality: 25

# Serveur Web pour streamer H.264
web_server:
  port: 80
  auth:
    username: admin
    password: !secret wifi_password

# API pour Home Assistant
api:
  services:
    # Service pour dÃ©marrer/arrÃªter le streaming
    - service: start_h264_stream
      then:
        - lambda: |-
            id(video_stream).start_streaming();

    - service: stop_h264_stream
      then:
        - lambda: |-
            id(video_stream).stop_streaming();
```

## ğŸ”§ ContrÃ´le Exposition (Image trop claire)

Vous avez mentionnÃ© que l'image est **trop Ã©clairÃ©e**. Ajoutez ces contrÃ´les :

```yaml
mipi_dsi_cam:
  id: main_camera
  sensor_type: sc202cs
  resolution: "1280x720"
  pixel_format: "YUV420"

  # ContrÃ´les d'exposition et de luminositÃ©
  camera_controls:
    # RÃ©duire l'exposition
    - id: V4L2_CID_EXPOSURE
      initial_value: 500  # Valeur plus basse = moins de lumiÃ¨re (essayez 200-800)

    # RÃ©duire le gain
    - id: V4L2_CID_GAIN
      initial_value: 50  # Valeur plus basse = moins de gain (essayez 30-100)

    # RÃ©duire la luminositÃ©
    - id: V4L2_CID_BRIGHTNESS
      initial_value: 0  # Valeur nÃ©gative = plus sombre (essayez -50 Ã  +50)

    # Activer l'auto-exposition avec target plus basse
    - id: V4L2_CID_EXPOSURE_AUTO
      initial_value: 1  # 1 = auto exposure
```

## ğŸ¯ Prochaines Ã‰tapes

1. **Tester avec RGB565 d'abord** : VÃ©rifier que la correction FPS fonctionne (devrait passer de 4 FPS Ã  30 FPS)

2. **Passer Ã  YUV420** : Changer `pixel_format: "YUV420"` dans la config

3. **ImplÃ©menter h264_stream** : CrÃ©er le composant selon le code ci-dessus

4. **Tester l'encodage** : VÃ©rifier que H.264 encoder fonctionne

5. **Ajouter sortie stream** : HTTP, MQTT, ou WebSocket selon vos besoins

## ğŸ“š RÃ©fÃ©rences

- ESP32-P4 H.264 Encoder API : `components/esp_h264/interface/include/`
- ESP Video Framework : `components/esp_video/include/`
- JPEG Encoder (similaire) : `components/esp_video/src/device/esp_video_jpeg_device.c`
- Exemples : `components/esp_video/exemples/`

## âš ï¸ Notes Importantes

1. **Format YUV420 pour H.264** : L'encodeur hardware ESP32-P4 nÃ©cessite YUV420 en entrÃ©e
2. **Performance** : H.264 hardware peut encoder 1280x720@30fps en temps rÃ©el
3. **Bitrate** : Ajuster selon qualitÃ© souhaitÃ©e (1-5 Mbps pour 720p)
4. **GOP (Group of Pictures)** : 30 = une I-frame toutes les 30 frames (1 seconde Ã  30fps)
5. **QP (Quantization)** : 25-26 = bonne qualitÃ©, 30-35 = qualitÃ© moyenne, 40+ = basse qualitÃ©
